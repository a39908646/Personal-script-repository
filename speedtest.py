import requests
import time
import urllib.parse
from urllib.parse import urlparse
import os

# ================= é…ç½®åŒºåŸŸ =================

# 1. æœ¬åœ° Clash ä»£ç†ç«¯å£
PROXY_PORT = 7890

# 2. Clash API è®¾ç½®
CLASH_API_URL = "http://127.0.0.1:9090"
CLASH_API_SECRET = "a0YcBKnR" 

# 3. æµ‹é€Ÿåœ°å€æ± 
URL_OPTIONS = {
    "1": {
        "name": "DMM è§†é¢‘æµ (æ—¥æœ¬ä¼˜åŒ–)",
        "url": "https://cc3001.dmm.co.jp/pv/KHYiQCINQ1k5qizjwUwcrp40YtyliqEbFA-WTLKJZLuTDns0IT2zrOtJ_4_ajQ69ebyf/118ftktabf288mhb.mp4"
    },
    "2": {
        "name": "GitHub Release (é€šç”¨å¤§æ–‡ä»¶)",
        "url": "https://github.com/AaronFeng753/Waifu2x-Extension-GUI/releases/download/v2.21.12/Waifu2x-Extension-GUI-v2.21.12-Portable.7z"
    }
}

# 4. æµ‹é€Ÿå‚æ•°
TEST_SIZE_MB = 100  # æœ€å¤§ä¸‹è½½é‡
TEST_DURATION = 10  # æœ€å¤§æµ‹é€Ÿæ—¶é•¿ï¼ˆç§’ï¼‰
TIMEOUT = 3

# 5. ä¿å­˜è·¯å¾„
SAVE_DIR = r"C:\Users\cloudwayne\Documents\speedtest"
# RESULT_FILENAME å°†åœ¨ä¿å­˜æ—¶åŠ¨æ€ç”Ÿæˆï¼ˆæ·»åŠ æ—¶é—´æˆ³ï¼‰

# ===========================================

def get_api_headers():
    headers = {"Content-Type": "application/json"}
    if CLASH_API_SECRET:
        headers["Authorization"] = f"Bearer {CLASH_API_SECRET}"
    return headers

# --- åŠŸèƒ½å‡½æ•° ---

def get_clash_mode():
    """è·å–å½“å‰ Clash æ¨¡å¼"""
    try:
        r = requests.get(f"{CLASH_API_URL}/configs", headers=get_api_headers(), timeout=2)
        return r.json().get('mode', 'Rule')
    except: return 'Rule'

def set_clash_mode(mode):
    """åˆ‡æ¢ Clash æ¨¡å¼"""
    try:
        requests.patch(f"{CLASH_API_URL}/configs", json={"mode": mode}, headers=get_api_headers(), timeout=2)
        print(f"âš™ï¸ ç³»ç»Ÿæ¨¡å¼å·²åˆ‡æ¢ä¸º: {mode}")
    except: pass

def get_proxy_groups():
    """è·å–æ‰€æœ‰ç­–ç•¥ç»„ä¾›ç”¨æˆ·é€‰æ‹©"""
    try:
        r = requests.get(f"{CLASH_API_URL}/proxies", headers=get_api_headers())
        data = r.json().get('proxies', {})
        # ç­›é€‰å‡ºæ‰€æœ‰ç­–ç•¥ç»„ç±»å‹ï¼ˆä¸åªæ˜¯ Selectorï¼‰
        group_types = ['Selector', 'URLTest', 'Fallback', 'LoadBalance']
        groups = [k for k, v in data.items()
                  if v.get('type') in group_types and k not in ['GLOBAL', 'REJECT']]
        return groups
    except: return []

def get_nodes_in_group(group_name):
    """è·å–æŒ‡å®šç»„å†…çš„èŠ‚ç‚¹"""
    try:
        url = f"{CLASH_API_URL}/proxies/{urllib.parse.quote(group_name)}"
        r = requests.get(url, headers=get_api_headers())
        return r.json().get('all', [])
    except: return []

def get_all_real_nodes():
    """è·å–æ‰€æœ‰çœŸå®èŠ‚ç‚¹ï¼ˆæ’é™¤ç­–ç•¥ç»„å’Œå†…ç½®ç­–ç•¥ï¼‰"""
    try:
        r = requests.get(f"{CLASH_API_URL}/proxies", headers=get_api_headers())
        data = r.json().get('proxies', {})
        real_nodes = []
        # æ’é™¤ç­–ç•¥ç»„ç±»å‹
        exclude_types = ['Selector', 'URL-Test', 'Fallback', 'Load-Balance', 'Direct', 'Reject', 'Relay', 'Compatible']
        # æ’é™¤ Mihomo å†…ç½®ç­–ç•¥å’Œå¸¸è§æ— æ•ˆèŠ‚ç‚¹
        exclude_names = ['DIRECT', 'REJECT', 'GLOBAL', 'PASS', 'Pass', 'COMPATIBLE']
        # æ’é™¤åŒ…å«è¿™äº›å…³é”®è¯çš„èŠ‚ç‚¹
        exclude_keywords = ['reject', 'drop', 'block', 'å¹¿å‘Š', 'ad-', 'adblock']

        for name, detail in data.items():
            # æ’é™¤ç‰¹å®šç±»å‹
            if detail['type'] in exclude_types:
                continue
            # æ’é™¤ç‰¹å®šåç§°ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            if name.upper() in [n.upper() for n in exclude_names]:
                continue
            # æ’é™¤åŒ…å«ç‰¹å®šå…³é”®è¯çš„èŠ‚ç‚¹ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            if any(keyword.lower() in name.lower() for keyword in exclude_keywords):
                continue
            real_nodes.append(name)
        return real_nodes
    except: return []

def select_url():
    print("\nè¯·é€‰æ‹©æµ‹é€Ÿåœ°å€:")
    print(f"1. {URL_OPTIONS['1']['name']}")
    print(f"2. {URL_OPTIONS['2']['name']}")
    print("3. è‡ªå®šä¹‰ URL")

    c = input("è¾“å…¥åºå· (é»˜è®¤1): ").strip()
    if c == '2': return URL_OPTIONS['2']['url']
    if c == '3': return input("è¾“å…¥URL: ").strip()
    return URL_OPTIONS['1']['url']

def switch_proxy(group, node):
    """åˆ‡æ¢èŠ‚ç‚¹"""
    try:
        url = f"{CLASH_API_URL}/proxies/{urllib.parse.quote(group)}"
        requests.put(url, json={"name": node}, headers=get_api_headers(), timeout=2)
        time.sleep(0.6) # ç­‰å¾…åˆ‡æ¢ç”Ÿæ•ˆ
    except: pass

def test_speed(node_name, url, current_idx=0, total=0):
    proxies = {"http": f"http://127.0.0.1:{PROXY_PORT}", "https": f"http://127.0.0.1:{PROXY_PORT}"}

    # ä» URL æå– Referer
    parsed = urlparse(url)
    referer = f"{parsed.scheme}://{parsed.netloc}/"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": referer,
        "Accept": "*/*",
        "Accept-Language": "en-US,en;q=0.9",
        "Connection": "keep-alive"
    }

    # åç§°æˆªæ–­æ˜¾ç¤º
    disp = (node_name[:25] + '..') if len(node_name)>25 else node_name
    # è¿›åº¦å‰ç¼€
    progress = f"[{current_idx}/{total}] " if total > 0 else ""
    print(f"{progress}æµ‹è¯• -> [{disp:<27}] ... ", end="", flush=True)

    try:
        start = time.time()
        with requests.get(url, proxies=proxies, headers=headers, stream=True, timeout=(TIMEOUT, TIMEOUT)) as r:
            if r.status_code == 403:
                print("âš ï¸ 403 Forbidden")
                return 0, "âš ï¸ 403 (åœ°åŒºé™åˆ¶)"
            if r.status_code != 200:
                print(f"âŒ HTTP {r.status_code}")
                return 0, f"âŒ HTTP {r.status_code}"

            downloaded = 0
            max_bytes = TEST_SIZE_MB * 1024 * 1024

            for chunk in r.iter_content(32768):
                if chunk:
                    downloaded += len(chunk)
                    elapsed = time.time() - start

                    # å®æ—¶æ˜¾ç¤ºé€Ÿåº¦
                    current_speed = (downloaded / 1024 / 1024) / elapsed if elapsed > 0 else 0
                    print(f"\r{progress}æµ‹è¯• -> [{disp:<27}] ... {current_speed:.1f} MB/s", end="", flush=True)

                    # åŒé‡é™åˆ¶ï¼šè¾¾åˆ°æ—¶é—´ä¸Šé™æˆ–æ•°æ®ä¸Šé™å°±åœæ­¢
                    if elapsed >= TEST_DURATION or downloaded >= max_bytes:
                        break

            dur = time.time() - start
            if dur <= 0: dur = 0.01
            speed = (downloaded / 1024 / 1024) / dur

            status_str = ""
            if speed > 10:
                print(f"\r{progress}æµ‹è¯• -> [{disp:<27}] ... ğŸš€ {speed:.2f} MB/s")
                status_str = f"ğŸš€ **{speed:.2f} MB/s**"
            elif speed > 3:
                print(f"\r{progress}æµ‹è¯• -> [{disp:<27}] ... âœ… {speed:.2f} MB/s")
                status_str = f"âœ… {speed:.2f} MB/s"
            else:
                print(f"\r{progress}æµ‹è¯• -> [{disp:<27}] ... ğŸ¢ {speed:.2f} MB/s")
                status_str = f"ğŸ¢ {speed:.2f} MB/s"

            return speed, status_str
    except requests.exceptions.Timeout:
        print(f"\r{progress}æµ‹è¯• -> [{disp:<27}] ... âŒ è¶…æ—¶")
        return 0, "âŒ è¶…æ—¶ Timeout"
    except:
        print(f"\r{progress}æµ‹è¯• -> [{disp:<27}] ... âŒ å¤±è´¥")
        return 0, "âŒ è¿æ¥å¤±è´¥ Error"

def save_markdown(results, title_info):
    try:
        if not os.path.exists(SAVE_DIR): os.makedirs(SAVE_DIR)
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        filename = f"speed_results_{timestamp}.md"
        path = os.path.join(SAVE_DIR, filename)
        
        with open(path, "w", encoding="utf-8") as f:
            f.write(f"# {title_info['title']}\n\n")
            f.write(f"- **æµ‹è¯•æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"- **æµ‹è¯•æ¨¡å¼**: {title_info['mode']}\n")
            f.write(f"- **èŠ‚ç‚¹æ€»æ•°**: {len(results)}\n\n")
            f.write("| æ’å | èŠ‚ç‚¹åç§° | é€Ÿåº¦ / çŠ¶æ€ |\n")
            f.write("| :--- | :--- | :--- |\n")
            
            for i, r in enumerate(results):
                safe_name = r['node'].replace("|", "\|")
                f.write(f"| {i+1} | {safe_name} | {r['msg']} |\n")
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {path}")
        try: os.startfile(SAVE_DIR)
        except: pass
    except Exception as e:
        print(f"ä¿å­˜å¤±è´¥: {e}")

# ================= ä¸»é€»è¾‘ =================

def main():
    print("--- Clash æµ‹é€Ÿå·¥å…· Pro ---\n")
    
    # 1. é€‰æ‹©æµ‹é€Ÿæ¨¡å¼
    print("è¯·é€‰æ‹©æµ‹é€ŸèŒƒå›´:")
    print("[1] æŒ‡å®šä»£ç†ç»„ (ä¾‹å¦‚: åªæµ‹ 'æ—¥æœ¬' ç»„)")
    print("[2] å…¨èŠ‚ç‚¹æš´åŠ›æµ‹é€Ÿ (æ‰«ææ‰€æœ‰èŠ‚ç‚¹ + å¼ºåˆ¶ Global)")
    mode_choice = input("\nè¾“å…¥åºå·: ").strip()
    
    target_nodes = []
    op_group = ""      # æ“ä½œçš„ç›®æ ‡ç»„
    is_global_test = False
    
    if mode_choice == '2':
        # å…¨èŠ‚ç‚¹æ¨¡å¼
        is_global_test = True
        op_group = "GLOBAL"
        target_nodes = get_all_real_nodes()
        if not target_nodes:
            print("âŒ æœªæ‰¾åˆ°èŠ‚ç‚¹ã€‚")
            return
    else:
        # ç»„æ¨¡å¼
        groups = get_proxy_groups()
        if not groups:
            print("âŒ æœªæ‰¾åˆ°ç­–ç•¥ç»„ã€‚")
            return
        print("\nå¯ç”¨ç­–ç•¥ç»„:")
        for i, g in enumerate(groups):
            print(f"{i+1}. {g}")
        
        try:
            g_idx = int(input("\né€‰æ‹©ç»„åºå·: ")) - 1
            if g_idx < 0 or g_idx >= len(groups):
                print("âŒ åºå·è¶…å‡ºèŒƒå›´")
                return
            op_group = groups[g_idx]
            target_nodes = get_nodes_in_group(op_group)
            # ç®€å•çš„è¿‡æ»¤
            filter_list = ["DIRECT", "REJECT", "è‡ªåŠ¨", "Auto", "æ•…éšœ"]
            target_nodes = [n for n in target_nodes if not any(x in n for x in filter_list)]
        except:
            print("è¾“å…¥é”™è¯¯")
            return

    print(f"\nå·²é€‰ç›®æ ‡: {op_group} | å¾…æµ‹èŠ‚ç‚¹: {len(target_nodes)} ä¸ª")
    
    # 2. é€‰æ‹© URL
    target_url = select_url()
    
    # 3. å‡†å¤‡ç¯å¢ƒ (å¦‚æœå…¨é‡æµ‹é€Ÿï¼Œåˆ‡æ¢ Global)
    origin_mode = get_clash_mode()
    if is_global_test and origin_mode != "Global":
        print("\nâ³ æ­£åœ¨åˆ‡æ¢è‡³ Global æ¨¡å¼ä»¥ç¡®ä¿å‡†ç¡®...")
        set_clash_mode("Global")
        time.sleep(1)

    # 4. å¼€å§‹æµ‹é€Ÿ
    results = []
    total_nodes = len(target_nodes)
    print("-" * 50)
    try:
        for idx, node in enumerate(target_nodes, 1):
            switch_proxy(op_group, node)
            s, m = test_speed(node, target_url, idx, total_nodes)
            results.append({"node": node, "speed": s, "msg": m})
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
    finally:
        # æµ‹é€Ÿå®Œæˆåè‡ªåŠ¨æ¢å¤ä¸º Rule æ¨¡å¼
        current_mode = get_clash_mode()
        if current_mode != "Rule":
            print("-" * 50)
            print(f"ğŸ”„ æ­£åœ¨æ¢å¤ Clash æ¨¡å¼ä¸º: Rule ...")
            set_clash_mode("Rule")

    # 5. ä¿å­˜
    results.sort(key=lambda x: x['speed'], reverse=True)
    
    title_info = {
        "title": "Clash å…¨èŠ‚ç‚¹æµ‹é€ŸæŠ¥å‘Š" if is_global_test else f"Clash åˆ†ç»„æµ‹é€ŸæŠ¥å‘Š ({op_group})",
        "mode": "Global (å¼ºåˆ¶å…¨å±€)" if is_global_test else f"Rule (åˆ†ç»„: {op_group})"
    }
    
    save_markdown(results, title_info)

if __name__ == "__main__":
    main()